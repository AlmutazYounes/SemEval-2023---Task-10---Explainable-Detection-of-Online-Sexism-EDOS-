{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "da354e39-cda0-4eb3-ae96-98b65e10339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "66024332-035b-4260-99b8-8d7dcb04e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(\"..\\edos_labelled_aggregated.csv\")\n",
    "\n",
    "data_type = \"dev\"\n",
    "labels = labels[labels[\"split\"] == data_type][[\"rewire_id\", \"label_sexist\"]]\n",
    "\n",
    "files = glob.glob(fr\"..\\ensemble\\{data_type}*.csv\")\n",
    "dfs = [pd.read_csv(i) for i in files]\n",
    "\n",
    "labels = dfs[0].merge(labels, on=\"rewire_id\", how=\"left\")[[\"rewire_id\", \"label_sexist\"]]\n",
    "y_true = labels.label_sexist.values\n",
    "\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac0936-d85c-422a-9765-50c72d3cc74f",
   "metadata": {},
   "source": [
    "# Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f6571334-b0c0-49cb-896d-16fbdb549278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft voting:  0.8492243670654323\n"
     ]
    }
   ],
   "source": [
    "probabilities = [i[[\"sexist\", \"not sexist\"]].values for i in dfs]\n",
    "\n",
    "def soft_voting(probabilities):\n",
    "    return np.mean(probabilities, axis=0)\n",
    "\n",
    "# Use soft voting to compute the final probabilities\n",
    "soft_probabilities = soft_voting(probabilities)\n",
    "soft_predictions = np.argmax(soft_probabilities, axis=1)\n",
    "soft_predictions = [\"sexist\" if i == 0 else \"not sexist\" for i in soft_predictions]\n",
    "soft = f1_score(y_true, soft_predictions, average='macro')\n",
    "print(\"Soft voting: \", soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f51c331-bd1c-42a8-bb0a-60eaebdb2fba",
   "metadata": {},
   "source": [
    "# Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "750ce75e-275d-4445-a24b-77e6ebe8e42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard voting:  0.8505323088002501\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the predicted labels\n",
    "label = []\n",
    "\n",
    "# Loop through each row of the first dataframe\n",
    "for row in range(len(dfs[0])):\n",
    "    # Count the number of \"sexist\" and \"not sexist\" labels across all dataframes\n",
    "    sexist_count = not_sexist_count = 0\n",
    "    for df in dfs:\n",
    "        if df[\"label_pred\"][row] == \"sexist\":\n",
    "            sexist_count += 1\n",
    "        else:\n",
    "            not_sexist_count += 1\n",
    "    \n",
    "    # Choose the label with the higher count\n",
    "    if sexist_count >= not_sexist_count:\n",
    "        label.append(\"sexist\")\n",
    "    else:\n",
    "        label.append(\"not sexist\")\n",
    "\n",
    "# Update the label_pred column of the first dataframe with the predicted labels\n",
    "df = dfs[0]\n",
    "df[\"label_pred\"] = label\n",
    "\n",
    "# Compute and print the F1 score\n",
    "hard = f1_score(y_true, df.label_pred.values, average='macro')\n",
    "print(\"hard voting: \", hard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae4c0b-57ad-4ee6-aa09-1f712cd8ca86",
   "metadata": {},
   "source": [
    "# highest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be67417e-ce5d-4a66-ac27-fc54bd3cc1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8474320777279842\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dfs)):\n",
    "    dfs[i][\"confidence\"] = abs(dfs[i][\"sexist\"] - dfs[i][\"not sexist\"])\n",
    "    dfs[i] = dfs[i][[\"rewire_id\", \"label_pred\", \"confidence\"]]\n",
    "    \n",
    "labels_position = []\n",
    "for row in range(len(dfs[0])):\n",
    "    a = [df[\"confidence\"][row] for df in dfs]\n",
    "    labels_position.append(np.argmax(a))\n",
    "    \n",
    "label=[]\n",
    "for j, i in enumerate(labels_position):\n",
    "    label.append(dfs[i][\"label_pred\"][j])\n",
    "    \n",
    "df = dfs[0][[\"rewire_id\"]]\n",
    "df[\"label_pred\"] = label\n",
    "\n",
    "# df.to_csv(\"../ensemble.csv\", index=False)\n",
    "max_prob = f1_score(y_true, df.label_pred.values, average='macro')\n",
    "print(max_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "895b477a-bfbd-4ad7-a4b0-67f237f101f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting                    : 84.92%\n",
      "Hard Voting                    : 85.05%\n",
      "highest probability Voting     : 84.74%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Soft Voting                    : {100 * soft:.2f}%\")\n",
    "print(f\"Hard Voting                    : {100 * hard:.2f}%\")\n",
    "print(f\"highest probability Voting     : {100 * max_prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206a36a-fe32-4309-9220-3b7035274cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e13135-9e5e-4cb6-859d-878ed059cc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
